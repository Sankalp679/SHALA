{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Assignment1(Intro_to_Machine_Learning).ipynb.txt",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9NbRkKP-M_Q",
        "colab_type": "text"
      },
      "source": [
        "Some of the techniques/concepts, which have been used in this solution, have not been covered in our course **SHALA-2020**. These concepts will be covered soon as the course progresses. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Z8gOB8Vvmajz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "bHG2QpiEmaj9",
        "colab_type": "code",
        "outputId": "8596ea3c-af3e-4fbe-a220-11f471a7a0b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "# importing some important packages\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv as csv\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6HfmGa2omakE",
        "colab_type": "code",
        "outputId": "a0668ee4-af99-4ea9-ebf1-64c1665b1b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# reading the dataset\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/shala2020/shala2020.github.io/master/Lecture_Materials/Assignments/MachineLearning/L1/attrition.csv')\n",
        "print('-'*30)\n",
        "print('size of training set: {}'.format(train.shape))\n",
        "print('-'*30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "size of training set: (1028, 34)\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NDmh3KTymakK",
        "colab_type": "code",
        "outputId": "f2573398-28fe-45e0-e2a3-7f81ebf7aec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# print the columns' names to decide the data type of each column numerical/categorical\n",
        "train.columns\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
              "       'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount',\n",
              "       'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'HourlyRate',\n",
              "       'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction',\n",
              "       'MaritalStatus', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
              "       'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
              "       'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears',\n",
              "       'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany',\n",
              "       'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager',\n",
              "       'ID'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "C6XYi3gymake",
        "colab_type": "code",
        "outputId": "4f1d7a7d-e4ce-47d8-dcce-d42162126905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "source": [
        "# to figure out the type of each column\n",
        "print(train.dtypes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Age                          int64\n",
            "Attrition                    int64\n",
            "BusinessTravel              object\n",
            "DailyRate                    int64\n",
            "Department                  object\n",
            "DistanceFromHome             int64\n",
            "Education                    int64\n",
            "EducationField              object\n",
            "EmployeeCount                int64\n",
            "EmployeeNumber               int64\n",
            "EnvironmentSatisfaction      int64\n",
            "Gender                      object\n",
            "HourlyRate                   int64\n",
            "JobInvolvement               int64\n",
            "JobLevel                     int64\n",
            "JobRole                     object\n",
            "JobSatisfaction              int64\n",
            "MaritalStatus               object\n",
            "MonthlyIncome                int64\n",
            "MonthlyRate                  int64\n",
            "NumCompaniesWorked           int64\n",
            "OverTime                    object\n",
            "PercentSalaryHike            int64\n",
            "PerformanceRating            int64\n",
            "RelationshipSatisfaction     int64\n",
            "StockOptionLevel             int64\n",
            "TotalWorkingYears            int64\n",
            "TrainingTimesLastYear        int64\n",
            "WorkLifeBalance              int64\n",
            "YearsAtCompany               int64\n",
            "YearsInCurrentRole           int64\n",
            "YearsSinceLastPromotion      int64\n",
            "YearsWithCurrManager         int64\n",
            "ID                           int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Jv2sb3famakm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_columns = ['BusinessTravel', 'Department', 'EducationField','Gender', \n",
        "                       'JobRole','MaritalStatus', 'OverTime']\n",
        "numerical_columns = ['Age', 'DailyRate','DistanceFromHome', 'Education', 'EnvironmentSatisfaction',\n",
        "                     'HourlyRate','JobInvolvement', 'JobLevel', 'JobSatisfaction',\n",
        "                     'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
        "                     'PercentSalaryHike', 'PerformanceRating',\n",
        "                     'RelationshipSatisfaction', 'StockOptionLevel',\n",
        "                     'TotalWorkingYears','TrainingTimesLastYear', \n",
        "                     'WorkLifeBalance', 'YearsAtCompany','YearsInCurrentRole',\n",
        "                     'YearsSinceLastPromotion', 'YearsWithCurrManager']#,'ID','EmployeeCount','EmployeeNumber'\n",
        "outputs = ['Attrition']\n",
        "# Dropping the irrelevant columns\n",
        "#train=train.drop(['Attrition'],axis=1)\n",
        "train=train.drop(['ID'],axis=1)\n",
        "train=train.drop(['EmployeeCount'],axis=1)\n",
        "train=train.drop(['EmployeeNumber'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "50R1VN7Amaks",
        "colab_type": "code",
        "outputId": "afe5b569-6d24-47ba-c01b-8e731e72265d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# converting the categorical and the numerical training data into tensors\n",
        "for category in categorical_columns:\n",
        "    train[category] = train[category].astype('category')\n",
        "    \n",
        "BusinessTravel = train['BusinessTravel'].cat.codes.values\n",
        "Department = train['Department'].cat.codes.values\n",
        "EducationField = train['EducationField'].cat.codes.values\n",
        "Gender = train['Gender'].cat.codes.values\n",
        "JobRole = train['JobRole'].cat.codes.values\n",
        "MaritalStatus = train['MaritalStatus'].cat.codes.values\n",
        "OverTime = train['OverTime'].cat.codes.values\n",
        "\n",
        "categorical_data = np.stack([BusinessTravel, Department, EducationField, Gender, \n",
        "                       JobRole, MaritalStatus, OverTime],1)\n",
        "\n",
        "# convert the categorical data into a tensor\n",
        "\n",
        "categorical_data = torch.tensor(categorical_data, dtype = torch.int64)\n",
        "# implementing One-hot encoding increases the accuracy\n",
        "categorical_data = torch.nn.functional.one_hot(categorical_data)\n",
        "\n",
        "\n",
        "print('type of the categorical data \\n {}'.format(type(categorical_data)))\n",
        "print('shape of the categorical data \\n {}'.format(categorical_data.shape))\n",
        "print('sample of the categorical data after converting to tensor \\n {}'.format(categorical_data[:5]))\n",
        "\n",
        "numerical_data = np.stack([train[col].values for col in numerical_columns],1)\n",
        "numerical_data = torch.tensor(numerical_data,dtype = torch.int64)#torch.long)# dtype = torch.float)\n",
        "print('-*'*30)\n",
        "print('type of the numerical data \\n {}'.format(type(numerical_data)))\n",
        "print('shape of the numerical data \\n {}'.format(numerical_data.shape))\n",
        "print('sample of the numerical data after converting to tensor \\n {}'.format(numerical_data[:2]))\n",
        "outputs = torch.tensor(train[outputs].values)\n",
        "print('-*'*30)\n",
        "print('output type :{}'.format(type(outputs)))\n",
        "print('output shape :{}'.format(outputs.shape))\n",
        "print(outputs[:5])\n",
        "categorical_data=categorical_data.view(categorical_data.shape[0],categorical_data.shape[1]*categorical_data.shape[2])\n",
        "print(categorical_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type of the categorical data \n",
            " <class 'torch.Tensor'>\n",
            "shape of the categorical data \n",
            " torch.Size([1028, 7, 9])\n",
            "sample of the categorical data after converting to tensor \n",
            " tensor([[[0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "         [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "        [[0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "        [[0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "         [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "         [1, 0, 0, 0, 0, 0, 0, 0, 0]]])\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "type of the numerical data \n",
            " <class 'torch.Tensor'>\n",
            "shape of the numerical data \n",
            " torch.Size([1028, 23])\n",
            "sample of the numerical data after converting to tensor \n",
            " tensor([[   41,  1102,     1,     2,     2,    94,     3,     2,     4,  5993,\n",
            "         19479,     8,    11,     3,     1,     0,     8,     0,     1,     6,\n",
            "             4,     0,     5],\n",
            "        [   49,   279,     8,     1,     3,    61,     2,     2,     2,  5130,\n",
            "         24907,     1,    23,     4,     4,     1,    10,     3,     3,    10,\n",
            "             7,     1,     7]])\n",
            "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
            "output type :<class 'torch.Tensor'>\n",
            "output shape :torch.Size([1028, 1])\n",
            "tensor([[1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0]])\n",
            "torch.Size([1028, 63])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YkVZs3YImak4",
        "colab_type": "code",
        "outputId": "d6c33c0e-c37e-4d8e-9e36-6021c682a13e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# concatenate the numerical and the catigorical data in one tensor to form the final data set\n",
        "data = torch.cat([categorical_data,  numerical_data], dim=1)\n",
        "#data = np.array(data)\n",
        "x = data.numpy()\n",
        "print('type of the data{}'.format(type(x)))\n",
        "print('size of the data{}'.format(x.shape))\n",
        "y = outputs.numpy()\n",
        "print('type of the output{}'.format(type(y)))\n",
        "print('size of the output{}'.format(y.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type of the data<class 'numpy.ndarray'>\n",
            "size of the data(1028, 86)\n",
            "type of the output<class 'numpy.ndarray'>\n",
            "size of the output(1028, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3o75mCbXmalR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# implementing different classifiers\n",
        "# import the important packages\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ec34ydBAmalW",
        "colab_type": "code",
        "outputId": "9f4068e9-9038-4069-cb2f-b17f11d07cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# dividing the dataset into training and validation datasets\n",
        "# I tried many values of the size of validation set, the value 20% gives the best results\n",
        "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size= 0.2, random_state=42,shuffle=True)\n",
        "print('the size of the training set{}'.format(x_train.shape))\n",
        "print('the size of the validation set{}'.format(x_val.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the size of the training set(822, 86)\n",
            "the size of the validation set(206, 86)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nBNPrlO4malc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Cross Validation\n",
        "# from sklearn.model_selection import KFold \n",
        "# n_splits = 5\n",
        "# kf = KFold(n_splits=5, random_state=42) \n",
        "# Total_Acc = 0.0\n",
        "# for train_index, test_index in kf.split(x):\n",
        "#     #print(\"Train:\", train_index, \"Validation:\",test_index)\n",
        "#     x_train, x_val = x[train_index], x[test_index] \n",
        "#     y_train, y_val = y[train_index], y[test_index]\n",
        "#     clf = AdaBoostClassifier()\n",
        "#     clf.fit(x_train, y_train)\n",
        "#     y_pred = clf.predict(x_val)\n",
        "#     Acc = accuracy_score(y_val, y_pred)\n",
        "#     Total_Acc =Total_Acc + Acc\n",
        "# print('validation accuracy = {}'.format(Total_Acc/n_splits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8cHZAxBUmalh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building the classifier\n",
        "# Deep Learning------It gave very low accuracy I guess because the training dataset size is small ---val_acc=0.85\n",
        "# clf = MLPClassifier(hidden_layer_sizes=(10,5,3), activation='relu', solver='adam', alpha=0.3, batch_size=200, learning_rate=  'adaptive', learning_rate_init=0.01\n",
        "#                     , max_iter=200, shuffle=True, random_state=42, momentum=0.9, nesterovs_momentum=True,\n",
        "#                     early_stopping=True, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=100,verbose=False)# accuracy = 0.88\n",
        "\n",
        "# # Random Forest Classifier\n",
        "# clf = RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=5, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',\n",
        "#                              max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=False, oob_score=False, n_jobs=None, random_state=None,\n",
        "#                               verbose=1, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)# accuracy = 0.88\n",
        "\n",
        "# #Support Vector Machine-----I tried various values of the parameters but the accuracy was low for all\n",
        "# clf = svm.SVC(C=0.01, kernel='rbf', degree=3, gamma=0.1, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False,\n",
        "#               max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None) # accuracy = 0.85\n",
        "\n",
        "# rng = np.random.RandomState(1)\n",
        "#clf = AdaBoostClassifier(RandomForestClassifier(n_estimators = 1000, max_depth = 3),n_estimators=10000, random_state=47)\n",
        "\n",
        "## I got the best results for AdaBoost classifier with the default values of the free parameters, \n",
        "## this ensemble classifier combines multiple classifiers to increase the accuracy of classifiers\n",
        "## It assigns the higher weight to wrong classified observations so that in the next iteration these observations will get the high probability for classification.\n",
        "## Also, It assigns the weight to the trained classifier in each iteration according to the accuracy of the classifier. The more accurate classifier will get high weight.\n",
        "## This process iterate until the complete training data fits without any error or until reached to the specified maximum number of estimators.\n",
        "clf = AdaBoostClassifier() #accuracy = 0.91414\n",
        "\n",
        "#clf = GradientBoostingClassifier()# accuracy= 0.859\n",
        "\n",
        "#clf = HistGradientBoostingClassifier()# accuracy = 0.854\n",
        "\n",
        "# svc=svm.SVC(probability=True, kernel='rbf')\n",
        "# clf = AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1)# accuracy = 0.85\n",
        "\n",
        "# clf = GaussianNB() #accuracy = 0.37\n",
        "\n",
        "\n",
        "# for ploy\n",
        "# clf = svm.SVC(C=1.0, kernel='rbf', degree=3, gamma=0.01, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False,\n",
        "#               max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
        "\n",
        "# # Decision Tree Classifier\n",
        "# clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=5, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
        "#                              max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "#                              class_weight=None, presort='deprecated', ccp_alpha=0.0) #accuracy = 0.83\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fvbxHAiUmalo",
        "colab_type": "code",
        "outputId": "0a40b64d-b897-4c40-897c-2230e7ee9ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "# training and testing the classifier\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred = clf.predict(x_val)\n",
        "print('the prediction array:\\n {}'.format(y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the prediction array:\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PZIQvUvQmalt",
        "colab_type": "code",
        "outputId": "76329beb-3f7f-470b-d80d-03b2956bdb8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# computing the validation accuracy\n",
        "accuracy_score(y_val, y_pred)\n",
        "#clf.score(x_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8689320388349514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nh5xfESymal1",
        "colab_type": "code",
        "outputId": "81f9dd68-b9ae-418b-a04c-614e35e6f8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# computing the confusion matrix\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "cm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[170,   7],\n",
              "       [ 20,   9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cse84X6Qmal6",
        "colab_type": "code",
        "outputId": "fecc6674-c9e6-4e4f-9292-d520cd5fb208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "sns.heatmap(cm, center=True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}